{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**ASSIGNMENT 2**"
      ],
      "metadata": {
        "id": "wIOv3Zq4n1kQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ2AeIZnnOzP"
      },
      "outputs": [],
      "source": [
        "#reading the dataset and doing data pre-processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Read the dataset\n",
        "data = pd.read_csv('/content/drug200.csv')\n",
        "\n",
        "\n",
        "\n",
        "#check for non-numeric values and missing values in each column\n",
        "for column in data.columns:\n",
        "    #check for non-numeric values\n",
        "    non_numeric_values = pd.to_numeric(data[column], errors='coerce').isna().sum()\n",
        "    if non_numeric_values > 0:\n",
        "        print(f\"Column '{column}' has {non_numeric_values} non-numeric value(s).\")\n",
        "\n",
        "    #check for missing values and replace them with the median\n",
        "    if data[column].isna().sum() > 0:\n",
        "        median_value = data[column].median()\n",
        "        data[column].fillna(median_value, inplace=True)\n",
        "\n",
        "\n",
        "#splittin gthe data into features and labels\n",
        "x = data.drop('Drug', axis=1)\n",
        "y = data['Drug']\n",
        "\n",
        "categorical_features = ['Sex','BP','Cholesterol']\n",
        "le = LabelEncoder()\n",
        "\n",
        "for feature in categorical_features:\n",
        "    x[feature] = le.fit_transform(x[feature])\n",
        "\n",
        "#performing one-hot encoding on the categorical features\n",
        "x = pd.get_dummies(x, columns=categorical_features)\n",
        "\n",
        "#splitting the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#performing feature scaling on numerical values\n",
        "numerical_features = ['Age', 'Na_to_K']\n",
        "scaler = StandardScaler()\n",
        "x_train[numerical_features] = scaler.fit_transform(x_train[numerical_features])\n",
        "x_test[numerical_features] = scaler.transform(x_test[numerical_features])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n"
      ],
      "metadata": {
        "id": "YndP9egMyxXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building the ANN model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(9,)))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(len(le.classes_), activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "#compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "RoAWKlrgn7if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=6)"
      ],
      "metadata": {
        "id": "RGDgQiOXxoUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing the model\n",
        "ypred = model.predict(x_test)"
      ],
      "metadata": {
        "id": "s68ERruX2lAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing the model with random data\n",
        "random_data = np.array([[45, 'M', 'LOW', 'NORMAL', 0.9]])\n",
        "model.predict(random_data)"
      ],
      "metadata": {
        "id": "XRvDFcGo5dCY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}